{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f0d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-google-genai chromadb pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002a275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAPLOu_CX_73zmAeZ2Ia_asWrB7B_7BADU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a53b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mevcut veritabanÄ± './gazi_db_hf' Ã¼zerinden yÃ¼kleniyor...\n",
      "ğŸ”„ BM25 indeksi iÃ§in veriler ChromaDB'den Ã§ekiliyor...\n",
      "ğŸš€ Hybrid Search (BM25 + Vector) yapÄ±landÄ±rÄ±lÄ±yor...\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://20e3174220d75757e6.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://20e3174220d75757e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define gemini api key\n",
    "import os\n",
    "# import the necessary library\n",
    "import time\n",
    "import sys\n",
    "import gradio as gr\n",
    "import fitz\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# --- MANUEL ENSEMBLE RETRIEVER TANIMI (KURULUM GEREKTÄ°RMEZ) ---\n",
    "# EnsembleRetriever import edilemezse, bu basit sÄ±nÄ±fÄ± kullanacaÄŸÄ±z.\n",
    "class SimpleEnsembleRetriever:\n",
    "    def __init__(self, retrievers, weights=None):\n",
    "        self.retrievers = retrievers\n",
    "        self.weights = weights or [1/len(retrievers)] * len(retrievers)\n",
    "\n",
    "    def invoke(self, query):\n",
    "        # Basit bir birleÅŸtirme mantÄ±ÄŸÄ±:\n",
    "        # TÃ¼m retrieverlardan sonuÃ§larÄ± al ve sÄ±rayla ekle (deduplication ile)\n",
    "        all_docs = []\n",
    "        seen_content = set()\n",
    "        \n",
    "        # Her retriever'Ä± Ã§alÄ±ÅŸtÄ±r\n",
    "        for retriever in self.retrievers:\n",
    "            docs = retriever.invoke(query)\n",
    "            for doc in docs:\n",
    "                # Ä°Ã§erik daha Ã¶nce eklenmediyse listeye ekle\n",
    "                # (Basit bir RRF mantÄ±ÄŸÄ± simÃ¼lasyonu)\n",
    "                if doc.page_content not in seen_content:\n",
    "                    all_docs.append(doc)\n",
    "                    seen_content.add(doc.page_content)\n",
    "        \n",
    "        # En fazla 6 dÃ¶kÃ¼man dÃ¶ndÃ¼r\n",
    "        return all_docs[:6]\n",
    "\n",
    "# Embedding Model AyarlarÄ±\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cuda'}, # GPU yoksa 'cpu' yapÄ±n\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "DB_PATH = \"./gazi_db_hf\"\n",
    "DATA_PATH = \"./data\"\n",
    "\n",
    "# BM25 iÃ§in dÃ¶kÃ¼man listesi tutucu\n",
    "docs_for_bm25 = []\n",
    "\n",
    "# --- VERÄ°TABANI KONTROL VE YÃœKLEME ---\n",
    "if os.path.exists(DB_PATH) and os.listdir(DB_PATH):\n",
    "    print(f\"âœ… Mevcut veritabanÄ± '{DB_PATH}' Ã¼zerinden yÃ¼kleniyor...\")\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=DB_PATH,\n",
    "        embedding_function=hf_embeddings,\n",
    "    )\n",
    "    \n",
    "    # Hybrid Search iÃ§in (BM25) mevcut verileri veritabanÄ±ndan Ã§ekmemiz gerek\n",
    "    print(\"ğŸ”„ BM25 indeksi iÃ§in veriler ChromaDB'den Ã§ekiliyor...\")\n",
    "    existing_data = vector_store.get() \n",
    "    \n",
    "    if existing_data['documents']:\n",
    "        for text, metadata in zip(existing_data['documents'], existing_data['metadatas']):\n",
    "            docs_for_bm25.append(Document(page_content=text, metadata=metadata))\n",
    "    else:\n",
    "        print(\"âš ï¸ VeritabanÄ± boÅŸ, data klasÃ¶rÃ¼ kontrol ediliyor...\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âš ï¸ VeritabanÄ± bulunamadÄ± veya eksik. '{DATA_PATH}' klasÃ¶rÃ¼ taranÄ±yor...\")\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"âŒ HATA: '{DATA_PATH}' klasÃ¶rÃ¼ bulunamadÄ±!\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"ğŸ“„ PDF dosyalarÄ± okunuyor...\")\n",
    "    raw_docs = []\n",
    "    pdf_files = [f for f in os.listdir(DATA_PATH) if f.endswith('.pdf')]\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"âŒ HATA: PDF dosyasÄ± bulunamadÄ±.\")\n",
    "        sys.exit()\n",
    "\n",
    "    for filename in pdf_files:\n",
    "        file_path = os.path.join(DATA_PATH, filename)\n",
    "        try:\n",
    "            doc = fitz.open(file_path)\n",
    "            for i, page in enumerate(doc):\n",
    "                text = page.get_text(\"text\")\n",
    "                if text.strip():\n",
    "                    raw_docs.append(Document(page_content=text, metadata={\"source\": file_path, \"page\": i}))\n",
    "            print(f\"   -> {filename} okundu.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸ HATA: {filename} okunamadÄ±: {e}\")\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(raw_docs)\n",
    "    docs_for_bm25 = splits \n",
    "\n",
    "    print(\"ğŸ’¾ VektÃ¶r veritabanÄ± oluÅŸturuluyor...\")\n",
    "    vector_store = Chroma.from_documents(documents=splits, embedding=hf_embeddings, persist_directory=DB_PATH)\n",
    "    print(\"âœ… VeritabanÄ± kaydedildi!\")\n",
    "\n",
    "# --- HYBRID SEARCH KURULUMU ---\n",
    "if not docs_for_bm25:\n",
    "    print(\"âŒ HATA: BM25 iÃ§in veri yok.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"ğŸš€ Hybrid Search (BM25 + Vector) yapÄ±landÄ±rÄ±lÄ±yor...\")\n",
    "\n",
    "# 1. BM25 Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(docs_for_bm25)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# 2. Chroma Retriever\n",
    "chroma_retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5, \"fetch_k\": 20})\n",
    "\n",
    "# 3. Ensemble Retriever (MANUEL SINIF KULLANILIYOR)\n",
    "ensemble_retriever = SimpleEnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, chroma_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# LLM settings\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.3)\n",
    "\n",
    "template = \"\"\"\n",
    "Sen Gazi Ãœniversitesi mevzuat asistanÄ±sÄ±n. GÃ¶revin aÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak sorularÄ± cevaplamaktÄ±r.\n",
    "\n",
    "## ğŸ“Œ KURALLAR\n",
    "1. Sadece verilen [BAÄLAM] iÃ§indeki bilgileri kullan.\n",
    "2. CevabÄ± oluÅŸtururken Ã¶nce ilgili yÃ¶netmelik maddesini bul, sonra aÃ§Ä±kla.\n",
    "3. EÄŸer soru bir prosedÃ¼rse, adÄ±mlarÄ± madde madde yaz.\n",
    "4. Bilgi yoksa \"Bu bilgi dokÃ¼manlarÄ±mda yer almÄ±yor\" de.\n",
    "\n",
    "## ğŸ—‚ï¸ [BAÄLAM]\n",
    "{context}\n",
    "\n",
    "## â“ Soru\n",
    "{question}\n",
    "\n",
    "## âœ… Cevap:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Basit retriever nesnesini bir Runnable'a dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in lambda kullanabiliriz\n",
    "# veya doÄŸrudan invoke metodunu Ã§aÄŸÄ±rabiliriz.\n",
    "retriever_runnable = RunnableLambda(lambda x: ensemble_retriever.invoke(x))\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever_runnable, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "def sohbet_et(message, history):\n",
    "    try:\n",
    "        sonuc = rag_chain_with_source.invoke(message)\n",
    "        cevap_metni = sonuc['answer']\n",
    "        dokumanlar = sonuc['context']\n",
    "        \n",
    "        display_text = \"\"\n",
    "        \n",
    "        for harf in cevap_metni:\n",
    "            display_text += harf\n",
    "            yield display_text\n",
    "            time.sleep(0.005)\n",
    "\n",
    "        if len(cevap_metni) > 20 and \"yer almÄ±yor\" not in cevap_metni.lower():\n",
    "            sources_text = \"\\n\\n---\\n### ğŸ“š **Kaynak DokÃ¼manlar**\\n\"\n",
    "            seen = set()\n",
    "            source_added = False\n",
    "            \n",
    "            for doc in dokumanlar:\n",
    "                source_path = doc.metadata.get(\"source\", \"Bilinmiyor\")\n",
    "                source_name = os.path.basename(source_path)\n",
    "                page = doc.metadata.get(\"page\", \"-\")\n",
    "                try: visible_page = int(page) + 1\n",
    "                except: visible_page = page\n",
    "\n",
    "                unique_id = f\"{source_name}-{page}\"\n",
    "                if unique_id not in seen:\n",
    "                    sources_text += f\"- ğŸ“„ *{source_name}* (Sayfa: {visible_page})\\n\"\n",
    "                    seen.add(unique_id)\n",
    "                    source_added = True\n",
    "            \n",
    "            if source_added:\n",
    "                display_text += sources_text\n",
    "                yield display_text \n",
    "                \n",
    "    except Exception as e:\n",
    "        yield f\"âŒ Bir hata oluÅŸtu: {str(e)}\"\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    demo = gr.ChatInterface(\n",
    "        fn=sohbet_et,\n",
    "        title=\"Gazi Ãœniversitesi Mevzuat AsistanÄ± (Hybrid Search)\",\n",
    "        description=\"Merhabalar! Hybrid Search (Vector + Keyword) ile sorularÄ±nÄ±zÄ± cevaplÄ±yorum.\",\n",
    "        examples=[\"Yaz okulu ÅŸartlarÄ± neler?\", \"DevamsÄ±zlÄ±k hakkÄ±m kaÃ§ saat?\", \"Yatay geÃ§iÅŸ nasÄ±l yapÄ±lÄ±r?\"],\n",
    "        submit_btn=\"GÃ¶nder\",\n",
    "    )\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4228c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
